{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from langdetect import detect\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/janramdohr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('bmh')\n",
    "nltk.download('stopwords')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survey data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/original/survey/survey.csv', parse_dates=['Start Date'], usecols = ['Start Date','introduction','floor','ground-floor','1-floor','2-floor','emotion','comfort','space usage','occupation','usage'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert survey data to correct timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['introduction'] == 'I understand, and I agree to participate in the survey']\n",
    "\n",
    "data['Start Date'] = data['Start Date'].dt.tz_localize('America/Denver')\n",
    "data['Start Date'] = data['Start Date'].dt.tz_convert('Europe/Amsterdam')\n",
    "\n",
    "def assign_place_id(row):\n",
    "    if row['floor'] == 'Ground floor' and row['ground-floor'] == 'Round tables by the three plants (across wooden staircase)':\n",
    "        return 1\n",
    "    elif row['floor'] == 'Ground floor' and row['ground-floor'] == 'Study corner next to the plant wall':\n",
    "        return 2\n",
    "    elif row['floor'] == '1st Floor' and row['1-floor'] == 'Green group study tables (between a row of plants and railing)':\n",
    "        return 3\n",
    "    elif row['floor'] == '1st Floor' and row['1-floor'] == 'Tables on the landing (with wooden floor) accessible by the black staircase':\n",
    "        return 3\n",
    "    elif row['floor'] == '1st Floor' and row['1-floor'] == 'Yellow/white chairs & tables (besides the wooden staircase)':\n",
    "        return 4\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "data['place_id'] = data.apply(assign_place_id, axis=1)\n",
    "\n",
    "data = data.drop(columns=['floor','ground-floor','1-floor','2-floor','introduction'])\n",
    "data = data.rename(columns={'usage':'frequent_use','occupation':'isStudent','space usage':'activity'})\n",
    "\n",
    "data['frequent_use'] = data['frequent_use'].map(dict(Yes=1, No=0))\n",
    "data['isStudent'] = data['isStudent'].map(dict(Yes=1, No=0))\n",
    "\n",
    "data['emotion'] = data['emotion'].astype(str)\n",
    "data['comfort'] = data['comfort'].astype(str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detect answers not written in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Date</th>\n",
       "      <th>emotion</th>\n",
       "      <th>comfort</th>\n",
       "      <th>activity</th>\n",
       "      <th>isStudent</th>\n",
       "      <th>frequent_use</th>\n",
       "      <th>place_id</th>\n",
       "      <th>language_emotion</th>\n",
       "      <th>language_comfort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-03 13:22:43+02:00</td>\n",
       "      <td>Rustig</td>\n",
       "      <td>8/10</td>\n",
       "      <td>Learning / Working in a group</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>af</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-05-09 11:21:03+02:00</td>\n",
       "      <td>Relaxed</td>\n",
       "      <td>Quite comfortable</td>\n",
       "      <td>Taking a break</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>so</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023-05-09 14:21:39+02:00</td>\n",
       "      <td>Rustgevend mooi uitzicht</td>\n",
       "      <td>Wel redelijk veel geluid</td>\n",
       "      <td>Learning / Working by yourself</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023-05-03 13:12:22+02:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>tl</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2023-05-11 11:32:21+02:00</td>\n",
       "      <td>Kalm, rustig</td>\n",
       "      <td>Wel goed, lekker rustig</td>\n",
       "      <td>Learning / Working in a group</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>et</td>\n",
       "      <td>af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2023-05-15 14:54:11+02:00</td>\n",
       "      <td>Calm</td>\n",
       "      <td>nan</td>\n",
       "      <td>Learning / Working in a group</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ca</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2023-05-09 14:51:01+02:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tl</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2023-05-10 10:17:34+02:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>tl</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2023-05-16 10:29:32+02:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tl</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2023-05-17 12:03:22+02:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>tl</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Start Date                   emotion  \\\n",
       "2  2023-05-03 13:22:43+02:00                   Rustig    \n",
       "18 2023-05-09 11:21:03+02:00                   Relaxed   \n",
       "26 2023-05-09 14:21:39+02:00  Rustgevend mooi uitzicht   \n",
       "32 2023-05-03 13:12:22+02:00                       nan   \n",
       "42 2023-05-11 11:32:21+02:00              Kalm, rustig   \n",
       "56 2023-05-15 14:54:11+02:00                      Calm   \n",
       "65 2023-05-09 14:51:01+02:00                       nan   \n",
       "71 2023-05-10 10:17:34+02:00                       nan   \n",
       "88 2023-05-16 10:29:32+02:00                       nan   \n",
       "95 2023-05-17 12:03:22+02:00                       nan   \n",
       "\n",
       "                     comfort                        activity  isStudent  \\\n",
       "2                       8/10   Learning / Working in a group        0.0   \n",
       "18         Quite comfortable                  Taking a break        1.0   \n",
       "26  Wel redelijk veel geluid  Learning / Working by yourself        1.0   \n",
       "32                       nan                             NaN        NaN   \n",
       "42  Wel goed, lekker rustig    Learning / Working in a group        1.0   \n",
       "56                       nan   Learning / Working in a group        1.0   \n",
       "65                       nan                             NaN        NaN   \n",
       "71                       nan                             NaN        NaN   \n",
       "88                       nan                             NaN        NaN   \n",
       "95                       nan                             NaN        NaN   \n",
       "\n",
       "    frequent_use  place_id language_emotion language_comfort  \n",
       "2            0.0       1.0               af          unknown  \n",
       "18           1.0       4.0               so               fr  \n",
       "26           1.0       3.0               nl               nl  \n",
       "32           NaN       3.0               tl               tl  \n",
       "42           1.0       4.0               et               af  \n",
       "56           1.0       4.0               ca               tl  \n",
       "65           NaN       1.0               tl               tl  \n",
       "71           NaN       3.0               tl               tl  \n",
       "88           NaN       NaN               tl               tl  \n",
       "95           NaN       4.0               tl               tl  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return 'unknown'\n",
    "\n",
    "data['language_emotion'] = data['emotion'].apply(detect_language)   \n",
    "data['language_comfort'] = data['comfort'].apply(detect_language)\n",
    "\n",
    "non_english = data[(data['language_emotion'] != 'en') & (data['language_comfort'] != 'en')]\n",
    "non_english"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translations based on deepl.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[2, 'emotion'] = 'Quiet'\n",
    "data.loc[26, 'emotion'] = 'Soothingly beautiful view'\n",
    "data.loc[26, 'comfort'] = 'Quite a lot of noise though'\n",
    "data.loc[42, 'emotion'] = 'Calm, quiet'\n",
    "data.loc[42, 'comfort'] = 'All right, nice and quiet'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize words and stencences and stem words for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(words):\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "data['emotion_tokens'] = data['emotion'].apply(nltk.word_tokenize)\n",
    "data['comfort_tokens'] = data['comfort'].apply(nltk.word_tokenize)\n",
    "\n",
    "data['emotion_tokens_stem'] = data['emotion_tokens'].apply(stem_words)\n",
    "data['comfort_tokens_stem'] = data['comfort_tokens'].apply(stem_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words_comfort = [word for sublist in data['comfort_tokens_stem'] for word in sublist]\n",
    "stemmed_words_emotion = [word for sublist in data['emotion_tokens_stem'] for word in sublist]\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "stemmed_words_comfort= [word for word in stemmed_words_comfort if word not in stop_words]\n",
    "stemmed_words_emotion= [word for word in stemmed_words_emotion if word not in stop_words]\n",
    "\n",
    "punctuation = string.punctuation + '’'\n",
    "\n",
    "stemmed_words_comfort = [word for word in stemmed_words_comfort if word not in punctuation]\n",
    "stemmed_words_emotion = [word for word in stemmed_words_emotion if word not in punctuation]\n",
    "\n",
    "fdist_comfort = nltk.probability.FreqDist(stemmed_words_comfort)\n",
    "fdist_emotion = nltk.probability.FreqDist(stemmed_words_emotion)\n",
    "\n",
    "em_dict = dict(fdist_emotion)\n",
    "com_dict = dict(fdist_comfort)\n",
    "df_em = df = pd.DataFrame.from_dict(em_dict, orient='index', columns=['Frequency'])\n",
    "df_com = df = pd.DataFrame.from_dict(com_dict, orient='index', columns=['Frequency'])\n",
    "df_em = df_em.sort_values(by='Frequency', ascending=False)\n",
    "df_com = df_com.sort_values(by='Frequency', ascending=False)\n",
    "df_com.to_csv('../data/processed/survey/freq_dist_com.csv', index_label='Word')\n",
    "df_em.to_csv('../data/processed/survey/freq_dist_em.csv', index_label='Word')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_rows = data.sample(n=15, random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_rows[['emotion','comfort']].to_csv('../data/processed/survey/validation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_sentiment(sentences):\n",
    "    sentiment_scores = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence =='nan':\n",
    "            sentiment_scores.append('nan')\n",
    "        else:\n",
    "            # tokenize the sentence and return tensors\n",
    "            inputs = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "            # get the model outputs\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "            # the model returns the logits\n",
    "            # the sentiment score can be computed using a softmax function\n",
    "            sentiment = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "\n",
    "            labels = ['negative', 'neutral', 'positive']\n",
    "            sentiment_label = labels[sentiment.argmax(dim=1).item()]\n",
    "\n",
    "            sentiment_scores.append(sentiment_label)\n",
    "    return sentiment_scores\n",
    "\n",
    "# add the sentiment scores to your dataframe\n",
    "data['comfort_sentiment'] = score_sentiment(data['comfort'])\n",
    "data['emotion_sentiment'] = score_sentiment(data['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_rows.rename(columns={'comfort':'comfort_sentiment_manual','emotion':'emotion_sentiment_manual'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_sentiment</th>\n",
       "      <th>emotion_sentiment_manual</th>\n",
       "      <th>comfort_x</th>\n",
       "      <th>comfort_sentiment</th>\n",
       "      <th>comfort_sentiment_manual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It is a nice place, with nice people, but I am very stressed</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Neutral; pretty okay but nothing special</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Fairly comfortable, nothing's explicitly wrong and the vibe is nice, but nothing stands out either</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         emotion  \\\n",
       "8   It is a nice place, with nice people, but I am very stressed   \n",
       "10                     Neutral; pretty okay but nothing special    \n",
       "\n",
       "   emotion_sentiment emotion_sentiment_manual  \\\n",
       "8           positive                 positive   \n",
       "10           neutral                  neutral   \n",
       "\n",
       "                                                                                             comfort_x  \\\n",
       "8                                                                                                  nan   \n",
       "10  Fairly comfortable, nothing's explicitly wrong and the vibe is nice, but nothing stands out either   \n",
       "\n",
       "   comfort_sentiment comfort_sentiment_manual  \n",
       "8                nan                      NaN  \n",
       "10          positive                  neutral  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the dataframes based on 'emotion' column\n",
    "merged_df = data.merge(validation_data, how='inner', on='emotion')\n",
    "\n",
    "# Check where emotion_sentiment != emotion_sentiment_manual or comfort_sentiment != manual_emotion_sentiment\n",
    "mismatch_df = merged_df.loc[(merged_df['emotion_sentiment'] != merged_df['emotion_sentiment_manual']) | (merged_df['comfort_sentiment'] != merged_df['comfort_sentiment_manual'])]\n",
    "\n",
    "# Print the rows where values do not match\n",
    "mismatch_df[['emotion','emotion_sentiment','emotion_sentiment_manual','comfort_x','comfort_sentiment','comfort_sentiment_manual']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspect based sentiment analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create environment parameter related list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light: ['light', 'illumin']\n",
      "temperature: ['cold']\n",
      "sound: ['quiet', 'nois', 'noisi', 'silenc']\n",
      "air: ['air']\n",
      "furniture: ['chair', 'screen', 'tabl', 'chairs/tabl']\n",
      "plants: ['plant', 'green', 'natur', 'greeneri']\n",
      "light: ['light', 'bright', 'dark', 'well-lit', 'illumin', 'sunlight', 'dim']\n",
      "temperature: ['temperatur', 'cold', 'warm', 'drafti', 'chilli', 'warmer', 'breez']\n",
      "sound: ['nois', 'noisi', 'loud', 'talk', 'sound', 'quiet', 'noic', 'echo-i', 'silenc', 'lout', 'noisey', 'silent', 'rumbl', 'voic']\n",
      "air: ['air', 'smell', 'fresh', 'breathabl']\n",
      "furniture: ['chair', 'tabl', 'coffe', 'seat', 'toilet', 'machin', 'stool', 'sofa', 'screen', 'furnitur']\n",
      "plants: ['plant', 'green', 'greeneri', 'natur', 'tree']\n"
     ]
    }
   ],
   "source": [
    "com_labels = pd.read_csv('../data/processed/survey/freq_dist_com_labeled.csv')\n",
    "em_labels = pd.read_csv('../data/processed/survey/freq_dist_em_labeled.csv')\n",
    "labels = ['light', 'temperature', 'sound', 'air', 'furniture', 'plants']\n",
    "label_word_arrays_em = {}\n",
    "label_word_arrays_com = {}\n",
    "\n",
    "# For each label, filter the dataframe and convert the 'Word' column to an array/list\n",
    "for label in labels:\n",
    "    label_word_arrays_em[label] = em_labels[em_labels['Label'] == label]['Word'].to_list()\n",
    "\n",
    "for label in labels:\n",
    "    label_word_arrays_com[label] = com_labels[com_labels['Label'] == label]['Word'].to_list()\n",
    "\n",
    "# Print the result\n",
    "for label, words in label_word_arrays_em.items():\n",
    "    print(f'{label}: {words}')\n",
    "\n",
    "for label, words in label_word_arrays_com.items():\n",
    "    print(f'{label}: {words}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.stem.PorterStemmer()\n",
    "\n",
    "def custom_split(text):\n",
    "    first_split = re.split('\\. |, |\\! | but ', text)\n",
    "\n",
    "    final_split = []\n",
    "\n",
    "    for sentence in first_split:\n",
    "        if ' and ' in sentence:\n",
    "            subsentences = sentence.split(' and ')\n",
    "            if any(len(subsentence.split()) <= 2 for subsentence in subsentences):\n",
    "                final_split.append(sentence)\n",
    "            else:\n",
    "                final_split.extend(subsentences)\n",
    "        else:\n",
    "            final_split.append(sentence)\n",
    "    \n",
    "    return final_split\n",
    "\n",
    "def stem_sentence(sentence):\n",
    "    words = nltk.tokenize.word_tokenize(sentence)\n",
    "    stemmed_words = [ps.stem(word) for word in words]\n",
    "    return stemmed_words\n",
    "\n",
    "def split_and_group(text, params):\n",
    "    split_sentences = custom_split(text)\n",
    "    \n",
    "    param_sentences = {param: [] for param in params.keys()}\n",
    "    \n",
    "    for subsentence in split_sentences:\n",
    "        stemmed_sentence = stem_sentence(subsentence)\n",
    "        for param, stems in params.items():\n",
    "            found_stem = False\n",
    "            for stem in stems:\n",
    "                if stem in stemmed_sentence:\n",
    "                    found_stem = True\n",
    "                    break  \n",
    "            \n",
    "            # Check if any stem was found\n",
    "            if found_stem:\n",
    "                param_sentences[param].append(subsentence.strip())\n",
    "    \n",
    "    return param_sentences\n",
    "\n",
    "grouped_sentences_comfort = data['comfort'].apply((lambda x: split_and_group(x,label_word_arrays_com)))\n",
    "grouped_sentences_emotion = data['emotion'].apply((lambda x: split_and_group(x,label_word_arrays_em)))\n",
    "\n",
    "for param in label_word_arrays_com.keys():\n",
    "    data['comfort_' + param] = grouped_sentences_comfort.apply(lambda x: x[param])\n",
    "\n",
    "for param in label_word_arrays_em.keys():\n",
    "    data['emotion_' + param] = grouped_sentences_emotion.apply(lambda x: x[param])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run sentiment analysis for all newly created columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['comfort_sound','comfort_light','comfort_furniture','comfort_plants','comfort_air','comfort_temperature','emotion_sound','emotion_light','emotion_furniture','emotion_plants','emotion_air','emotion_temperature']\n",
    "\n",
    "for column in columns:\n",
    "    joined = data[column].apply(lambda x: ', '.join(x)if x else 'nan')\n",
    "    data[column+ '_sentiment'] = score_sentiment(joined)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up helper columns and export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =data.drop(columns=['language_emotion',\n",
    "                   'language_comfort',\n",
    "                   'comfort_temperature',\n",
    "                   'comfort_sound',\n",
    "                   'comfort_air',\n",
    "                   'comfort_furniture',\n",
    "                   'comfort_plants',\n",
    "                   'comfort_light',\n",
    "                   'emotion_temperature',\n",
    "                   'emotion_sound',\n",
    "                   'emotion_air',\n",
    "                   'emotion_furniture',\n",
    "                   'emotion_plants',\n",
    "                   'emotion_light'])\n",
    "\n",
    "data = data.replace('nan', None)\n",
    "data.to_csv('../data/processed/survey/survey_sentiment.csv',na_rep='', index=False, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
